{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e459a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch tensorflow scikit-learn pandas numpy matplotlib seaborn nltk imbalanced-learn wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9990c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e14fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "Installing matplotlib...\n",
      "✓ matplotlib installed successfully\n",
      "Installing seaborn...\n",
      "✓ seaborn installed successfully\n",
      "Installing scikit-learn...\n",
      "✓ scikit-learn installed successfully\n",
      "✓ pandas already installed\n",
      "✓ numpy already installed\n",
      "Installing nltk...\n",
      "✓ nltk installed successfully\n",
      "Installing imbalanced-learn...\n",
      "✓ imbalanced-learn installed successfully\n",
      "Installing transformers[torch]...\n",
      "✓ transformers[torch] installed successfully\n",
      "✓ torch already installed\n",
      "Installing datasets...\n",
      "✓ datasets installed successfully\n",
      "Installing wordcloud...\n",
      "✓ wordcloud installed successfully\n",
      "✓ jupyter already installed\n",
      "\n",
      "✅ All packages installed!\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: COMPLETE INSTALLATION\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "def install_and_import(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "        print(f\"✓ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✓ {package} installed successfully\")\n",
    "\n",
    "# Install all required packages\n",
    "packages = [\n",
    "    'matplotlib',\n",
    "    'seaborn', \n",
    "    'scikit-learn',\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'nltk',\n",
    "    'imbalanced-learn',\n",
    "    'transformers[torch]',\n",
    "    'torch',\n",
    "    'datasets',\n",
    "    'wordcloud',\n",
    "    'jupyter'\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages:\n",
    "    install_and_import(package)\n",
    "\n",
    "print(\"\\n✅ All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b0c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89014ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing essential packages only (this will be fast)...\n",
      "Installing pandas...\n",
      "Installing numpy...\n",
      "Installing scikit-learn...\n",
      "Installing nltk...\n",
      "✅ Essential packages installed!\n",
      "✅ Visualization packages installed!\n",
      "\n",
      "🚀 READY! Now let's proceed with the core model...\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: MINIMAL FAST INSTALLATION\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Install ONLY the essential packages\n",
    "essential_packages = [\n",
    "    'pandas',\n",
    "    'numpy', \n",
    "    'scikit-learn',\n",
    "    'nltk'\n",
    "]\n",
    "\n",
    "print(\"Installing essential packages only (this will be fast)...\")\n",
    "for package in essential_packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
    "\n",
    "print(\"✅ Essential packages installed!\")\n",
    "\n",
    "# Now install visualization packages separately (optional)\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\", \"seaborn\", \"--quiet\"])\n",
    "    print(\"✅ Visualization packages installed!\")\n",
    "except:\n",
    "    print(\"⚠️  Visualization packages skipped (not essential)\")\n",
    "\n",
    "print(\"\\n🚀 READY! Now let's proceed with the core model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e038124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment ready! Starting model training...\n",
      "Generating dataset...\n",
      "Dataset ready: 3000 samples\n",
      "Training model...\n",
      "✅ Model trained! Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       bank_scam       1.00      1.00      1.00       122\n",
      "        fake_job       1.00      1.00      1.00       113\n",
      "investment_fraud       1.00      1.00      1.00       111\n",
      "      legitimate       1.00      1.00      1.00       113\n",
      "        phishing       1.00      1.00      1.00       141\n",
      "\n",
      "        accuracy                           1.00       600\n",
      "       macro avg       1.00      1.00      1.00       600\n",
      "    weighted avg       1.00      1.00      1.00       600\n",
      "\n",
      "\n",
      "🧪 Testing the model:\n",
      "==================================================\n",
      "Message: You've won $500000! Pay $50 processing fee to claim your prize\n",
      "Result: 🚨 SCAM - fake_job (Confidence: 0.60)\n",
      "----------------------------------------\n",
      "Message: Your Amazon order has been shipped\n",
      "Result: ✅ LEGITIMATE - legitimate (Confidence: 0.56)\n",
      "----------------------------------------\n",
      "Message: Urgent: Your bank account will be suspended. Verify now\n",
      "Result: 🚨 SCAM - phishing (Confidence: 0.88)\n",
      "----------------------------------------\n",
      "Message: Meeting reminder: Team sync at 3 PM tomorrow\n",
      "Result: ✅ LEGITIMATE - legitimate (Confidence: 1.00)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: SIMPLIFIED SCAM DETECTION MODEL (FAST)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Download minimal NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "print(\"✅ Environment ready! Starting model training...\")\n",
    "\n",
    "# --- SIMPLIFIED DATASET GENERATION ---\n",
    "def generate_fast_dataset(num_samples=5000):\n",
    "    \"\"\"Fast dataset generation with essential scam patterns\"\"\"\n",
    "    \n",
    "    scam_patterns = {\n",
    "        'phishing': [\n",
    "            \"Urgent: Your account will be suspended. Verify now\",\n",
    "            \"Security Alert: Unusual login detected\",\n",
    "            \"Your bank account needs immediate attention\",\n",
    "            \"Update your payment information to avoid service disruption\"\n",
    "        ],\n",
    "        'fake_job': [\n",
    "            \"Congratulations! You're hired. Pay for training\",\n",
    "            \"Work from home opportunity. Send money for starter kit\",\n",
    "            \"High paying job no experience needed. Pay processing fee\"\n",
    "        ],\n",
    "        'bank_scam': [\n",
    "            \"CBE Alert: Your account has been compromised\",\n",
    "            \"Dashen Bank: Suspicious transaction. Verify your PIN\",\n",
    "            \"Bank of Abyssinia: Account freeze warning\"\n",
    "        ],\n",
    "        'investment_fraud': [\n",
    "            \"Double your money in 24 hours. Invest now\",\n",
    "            \"Guaranteed 500% return on crypto investment\"\n",
    "        ],\n",
    "        'legitimate': [\n",
    "            \"Your order has been shipped and will arrive tomorrow\",\n",
    "            \"Meeting reminder: Team sync at 2 PM\",\n",
    "            \"Your monthly statement is ready for review\",\n",
    "            \"Thank you for your application\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for category, patterns in scam_patterns.items():\n",
    "        samples_per_pattern = num_samples // (len(patterns) * len(scam_patterns))\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            for _ in range(samples_per_pattern):\n",
    "                # Simple variation\n",
    "                message = pattern\n",
    "                if np.random.random() > 0.5 and category != 'legitimate':\n",
    "                    message = message + \" immediately!\"\n",
    "                \n",
    "                data.append(message)\n",
    "                labels.append(category)\n",
    "    \n",
    "    return pd.DataFrame({'text': data, 'label': labels})\n",
    "\n",
    "print(\"Generating dataset...\")\n",
    "df = generate_fast_dataset(3000)  # Smaller dataset for speed\n",
    "print(f\"Dataset ready: {len(df)} samples\")\n",
    "\n",
    "# --- SIMPLE PREPROCESSING ---\n",
    "def simple_clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(simple_clean)\n",
    "\n",
    "# --- FAST TRAINING ---\n",
    "print(\"Training model...\")\n",
    "\n",
    "# TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['label'])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)  # Smaller for speed\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"✅ Model trained! Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# --- SIMPLE PREDICTION FUNCTION ---\n",
    "def predict_scam(message):\n",
    "    cleaned = simple_clean(message)\n",
    "    features = vectorizer.transform([cleaned])\n",
    "    prediction = model.predict(features)[0]\n",
    "    probability = model.predict_proba(features)[0]\n",
    "    \n",
    "    return {\n",
    "        'prediction': le.inverse_transform([prediction])[0],\n",
    "        'confidence': np.max(probability),\n",
    "        'is_scam': le.inverse_transform([prediction])[0] != 'legitimate',\n",
    "        'all_probabilities': dict(zip(le.classes_, probability))\n",
    "    }\n",
    "\n",
    "# Test the model\n",
    "test_messages = [\n",
    "    \"You've won $500000! Pay $50 processing fee to claim your prize\",\n",
    "    \"Your Amazon order has been shipped\",\n",
    "    \"Urgent: Your bank account will be suspended. Verify now\",\n",
    "    \"Meeting reminder: Team sync at 3 PM tomorrow\"\n",
    "]\n",
    "\n",
    "print(\"\\n🧪 Testing the model:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in test_messages:\n",
    "    result = predict_scam(msg)\n",
    "    status = \"🚨 SCAM\" if result['is_scam'] else \"✅ LEGITIMATE\"\n",
    "    print(f\"Message: {msg}\")\n",
    "    print(f\"Result: {status} - {result['prediction']} (Confidence: {result['confidence']:.2f})\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e4e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully!\n",
      "📁 Files created:\n",
      "   - label_encoder.pkl\n",
      "   - model_info.json\n",
      "   - random_forest_model.pkl\n",
      "   - tfidf_vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: SAVE THE MODEL AND CREATE INTEGRATION FILES\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create directory for model files\n",
    "os.makedirs('scam_model', exist_ok=True)\n",
    "\n",
    "# Save all components\n",
    "joblib.dump(model, 'scam_model/random_forest_model.pkl')\n",
    "joblib.dump(vectorizer, 'scam_model/tfidf_vectorizer.pkl')\n",
    "joblib.dump(le, 'scam_model/label_encoder.pkl')\n",
    "\n",
    "# Save model metadata\n",
    "model_info = {\n",
    "    \"model_type\": \"RandomForest\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"training_date\": pd.Timestamp.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"accuracy\": float(accuracy),\n",
    "    \"classes\": le.classes_.tolist(),\n",
    "    \"feature_count\": X.shape[1],\n",
    "    \"training_samples\": len(df)\n",
    "}\n",
    "\n",
    "with open('scam_model/model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"✅ Model saved successfully!\")\n",
    "print(\"📁 Files created:\")\n",
    "for file in os.listdir('scam_model'):\n",
    "    print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1019ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Flask API created: scam_api.py\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: CREATE FLASK API FOR NEXT.JS INTEGRATION\n",
    "flask_api_code = '''\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import joblib\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for Next.js frontend\n",
    "\n",
    "class ScamDetector:\n",
    "    def __init__(self):\n",
    "        # Load model components\n",
    "        self.model = joblib.load('scam_model/random_forest_model.pkl')\n",
    "        self.vectorizer = joblib.load('scam_model/tfidf_vectorizer.pkl')\n",
    "        self.le = joblib.load('scam_model/label_encoder.pkl')\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\\\s]', '', text)\n",
    "        return text\n",
    "    \n",
    "    def predict(self, message):\n",
    "        cleaned = self.clean_text(message)\n",
    "        features = self.vectorizer.transform([cleaned])\n",
    "        prediction = self.model.predict(features)[0]\n",
    "        probability = self.model.predict_proba(features)[0]\n",
    "        \n",
    "        return {\n",
    "            'prediction': self.le.inverse_transform([prediction])[0],\n",
    "            'confidence': float(np.max(probability)),\n",
    "            'is_scam': self.le.inverse_transform([prediction])[0] != 'legitimate',\n",
    "            'all_probabilities': dict(zip(self.le.classes_, probability.tolist()))\n",
    "        }\n",
    "\n",
    "# Initialize detector\n",
    "detector = ScamDetector()\n",
    "\n",
    "@app.route('/api/predict', methods=['POST'])\n",
    "def predict_scam():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        \n",
    "        if not data or 'message' not in data:\n",
    "            return jsonify({'error': 'No message provided'}), 400\n",
    "        \n",
    "        message = data['message']\n",
    "        \n",
    "        if not message.strip():\n",
    "            return jsonify({'error': 'Empty message'}), 400\n",
    "        \n",
    "        result = detector.predict(message)\n",
    "        return jsonify(result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({'status': 'healthy', 'model': 'scam_detector_v1'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)\n",
    "'''\n",
    "\n",
    "# Save the Flask API\n",
    "with open('scam_api.py', 'w') as f:\n",
    "    f.write(flask_api_code)\n",
    "\n",
    "print(\"✅ Flask API created: scam_api.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41df58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API test function created. Run test_api_locally() after starting the server.\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: TEST THE API (Simulate Next.js calling the API)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def test_api_locally():\n",
    "    \"\"\"Test our API with sample messages\"\"\"\n",
    "    \n",
    "    # This simulates what your Next.js app would do\n",
    "    api_url = \"http://localhost:5000/api/predict\"\n",
    "    \n",
    "    test_messages = [\n",
    "        \"You won $1,000,000! Pay $50 to claim your prize now!\",\n",
    "        \"Your package will be delivered tomorrow\",\n",
    "        \"Urgent: Your bank account needs verification immediately\",\n",
    "        \"Meeting scheduled for 3 PM in conference room\"\n",
    "    ]\n",
    "    \n",
    "    print(\"🧪 Testing API integration:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for message in test_messages:\n",
    "        try:\n",
    "            response = requests.post(api_url, json={'message': message})\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                status = \"🚨 SCAM\" if result['is_scam'] else \"✅ LEGITIMATE\"\n",
    "                print(f\"Message: {message}\")\n",
    "                print(f\"Result: {status} - {result['prediction']}\")\n",
    "                print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "                print(\"-\" * 40)\n",
    "            else:\n",
    "                print(f\"❌ Error: {response.status_code} - {response.text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ API call failed: {e}\")\n",
    "\n",
    "print(\"API test function created. Run test_api_locally() after starting the server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2da1009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Next.js integration examples created with emojis!\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE: Keep emojis with proper encoding\n",
    "nextjs_code = '''\n",
    "// Next.js API Route: pages/api/check-scam.js\n",
    "export default async function handler(req, res) {\n",
    "  if (req.method !== 'POST') {\n",
    "    return res.status(405).json({ error: 'Method not allowed' });\n",
    "  }\n",
    "\n",
    "  try {\n",
    "    const { message } = req.body;\n",
    "\n",
    "    if (!message) {\n",
    "      return res.status(400).json({ error: 'Message is required' });\n",
    "    }\n",
    "\n",
    "    // Call our Python Flask API\n",
    "    const flaskResponse = await fetch('http://localhost:5000/api/predict', {\n",
    "      method: 'POST',\n",
    "      headers: {\n",
    "        'Content-Type': 'application/json',\n",
    "      },\n",
    "      body: JSON.stringify({ message }),\n",
    "    });\n",
    "\n",
    "    if (!flaskResponse.ok) {\n",
    "      throw new Error('Failed to get prediction from AI service');\n",
    "    }\n",
    "\n",
    "    const prediction = await flaskResponse.json();\n",
    "    \n",
    "    res.status(200).json(prediction);\n",
    "  } catch (error) {\n",
    "    console.error('Scam detection error:', error);\n",
    "    res.status(500).json({ error: 'Internal server error' });\n",
    "  }\n",
    "}\n",
    "\n",
    "// React Component Example: components/ScamChecker.js\n",
    "import { useState } from 'react';\n",
    "\n",
    "export default function ScamChecker() {\n",
    "  const [message, setMessage] = useState('');\n",
    "  const [result, setResult] = useState(null);\n",
    "  const [loading, setLoading] = useState(false);\n",
    "\n",
    "  const checkScam = async () => {\n",
    "    if (!message.trim()) return;\n",
    "    \n",
    "    setLoading(true);\n",
    "    try {\n",
    "      const response = await fetch('/api/check-scam', {\n",
    "        method: 'POST',\n",
    "        headers: {\n",
    "          'Content-Type': 'application/json',\n",
    "        },\n",
    "        body: JSON.stringify({ message }),\n",
    "      });\n",
    "      \n",
    "      const data = await response.json();\n",
    "      setResult(data);\n",
    "    } catch (error) {\n",
    "      console.error('Error:', error);\n",
    "      setResult({ error: 'Failed to check message' });\n",
    "    } finally {\n",
    "      setLoading(false);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div className=\"p-6 max-w-md mx-auto bg-white rounded-xl shadow-md\">\n",
    "      <h2 className=\"text-2xl font-bold mb-4\">Scam Detection</h2>\n",
    "      \n",
    "      <textarea\n",
    "        value={message}\n",
    "        onChange={(e) => setMessage(e.target.value)}\n",
    "        placeholder=\"Paste message to check for scams...\"\n",
    "        className=\"w-full p-3 border border-gray-300 rounded-md mb-4\"\n",
    "        rows=\"4\"\n",
    "      />\n",
    "      \n",
    "      <button\n",
    "        onClick={checkScam}\n",
    "        disabled={loading}\n",
    "        className=\"w-full bg-blue-600 text-white py-2 px-4 rounded-md hover:bg-blue-700 disabled:bg-gray-400\"\n",
    "      >\n",
    "        {loading ? 'Checking...' : 'Check for Scams'}\n",
    "      </button>\n",
    "      \n",
    "      {result && (\n",
    "        <div className={`mt-4 p-4 rounded-md ${\n",
    "          result.is_scam ? 'bg-red-100 border border-red-300' : 'bg-green-100 border border-green-300'\n",
    "        }`}>\n",
    "          <h3 className={`font-bold ${result.is_scam ? 'text-red-800' : 'text-green-800'}`}>\n",
    "            {result.is_scam ? '🚨 Potential Scam Detected' : '✅ Likely Legitimate'}\n",
    "          </h3>\n",
    "          <p>Type: {result.prediction}</p>\n",
    "          <p>Confidence: {(result.confidence * 100).toFixed(1)}%</p>\n",
    "        </div>\n",
    "      )}\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "'''\n",
    "\n",
    "# Force UTF-8 encoding\n",
    "try:\n",
    "    with open('nextjs_integration_examples.js', 'w', encoding='utf-8') as f:\n",
    "        f.write(nextjs_code)\n",
    "    print(\"✅ Next.js integration examples created with emojis!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with emojis: {e}\")\n",
    "    # Fallback without emojis\n",
    "    nextjs_code = nextjs_code.replace('🚨', 'ALERT:').replace('✅', 'SAFE:')\n",
    "    with open('nextjs_integration_examples.js', 'w', encoding='utf-8') as f:\n",
    "        f.write(nextjs_code)\n",
    "    print(\"✅ Next.js integration examples created (emoji-free version)!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
